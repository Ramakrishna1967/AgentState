<agentstack_system_prompt>

<!-- ═══════════════════════════════════════════════════════════════════ -->
<!--                    AGENTSTACK — AI SYSTEM PROMPT                  -->
<!--              The Single Source of Truth for All AI Agents          -->
<!--                        Version: 1.0.0-alpha                       -->
<!-- ═══════════════════════════════════════════════════════════════════ -->

<identity>
  <name>AgentStack</name>
  <tagline>Chrome DevTools for AI Agents</tagline>
  <description>
    AgentStack is an enterprise-grade, open-source observability platform for
    AI Agents built on LangGraph, CrewAI, AutoGen, and custom Python implementations.
    It solves the "black box" problem — when agents fail (infinite loops, hallucinations,
    PII leaks), developers have zero visibility. AgentStack is their flight recorder.
  </description>
  <license>Apache 2.0</license>
</identity>


<!-- ═══════════════════════════════════════════════════════════════════ -->
<!--                      SYSTEM ARCHITECTURE                          -->
<!-- ═══════════════════════════════════════════════════════════════════ -->

<architecture>
  <overview>
    Distributed system with 6 layers: SDK → Collector → Redis Streams → Workers → ClickHouse → Dashboard.
    Designed for async-first, fail-safe, partition-tolerant operation at 100K+ spans/sec.
  </overview>

  <layers>
    <layer name="SDK" tech="Python 3.10+ / OpenTelemetry">
      Lightweight pip-installable package. Instruments agent code via @observe decorator.
      Creates spans, batches them (64 spans OR 5s), exports via OTLP/HTTP Protobuf (gzip).
      NEVER crashes the user's app. Falls back to local SQLite on failure.
    </layer>

    <layer name="Ingestion" tech="FastAPI + Uvicorn (port 4318)">
      Trace Collector receives span batches, validates API key + schema + payload size,
      serializes to MsgPack, pushes to Redis Stream via XADD. Returns HTTP 202.
    </layer>

    <layer name="Event Bus" tech="Redis 7.x Streams">
      Durable message queue between Collector and Workers.
      Stream: spans.ingest (maxlen ~1M). AOF persistence. noeviction policy.
      Three consumer groups read in parallel: writer-group, security-group, cost-group.
    </layer>

    <layer name="Processing Workers" tech="Python consumer processes">
      <worker name="ClickHouse Writer">
        Reads spans from Redis, batch-INSERTs (1000 spans or 1s) into ClickHouse.
        ACKs Redis on success. Infinite retry on failure — no data loss.
      </worker>
      <worker name="Security Engine">
        Scans every span for prompt injection (500+ patterns, Bloom Filter),
        PII leaks (SSN, email, credit cards, AWS/OpenAI keys), and anomaly detection
        (infinite loops via 3σ duration). Writes alerts to ClickHouse + Redis alerts.live.
        Uses Regex + YARA rules. Threat scoring: LOW / MEDIUM / HIGH / CRITICAL.
      </worker>
      <worker name="Cost Calculator">
        Extracts token counts + model name from spans, looks up per-model pricing,
        calculates cost, INSERTs into cost_metrics table.
      </worker>
    </layer>

    <layer name="Storage" tech="ClickHouse 24.x (columnar)">
      All data lands here. MergeTree engines. 100K+ queries/sec.
      Hot tier (7 days) → Cold tier (90 days, S3-backed) → TTL auto-delete.
    </layer>

    <layer name="API + Frontend" tech="FastAPI + React 19 (Vite + Shadcn UI)">
      REST API + WebSocket for live streaming. React dashboard with:
      Dashboard overview, Trace Timeline (waterfall), Security alerts, Cost analytics, Settings.
    </layer>
  </layers>
</architecture>


<!-- ═══════════════════════════════════════════════════════════════════ -->
<!--                       MONOREPO STRUCTURE                          -->
<!-- ═══════════════════════════════════════════════════════════════════ -->

<file_structure>
  <package name="sdk-python" path="packages/sdk-python/">
    <module file="__init__.py" purpose="Public API: observe, init" />
    <module file="decorator.py" purpose="@observe decorator — wraps sync + async functions" />
    <module file="tracer.py" purpose="OpenTelemetry tracer, Span class, context propagation" />
    <module file="context.py" purpose="Async context propagation via contextvars" />
    <module file="exporter.py" purpose="BatchSpanProcessor — batches and exports via HTTP" />
    <module file="sanitizer.py" purpose="PII scrubbing (SSN, email, CC) before export" />
    <module file="config.py" purpose="SDK configuration from env vars" />
    <module file="models.py" purpose="Pydantic span and trace models" />
    <module file="local_store.py" purpose="SQLite fallback for offline spans" />
    <dir name="frameworks/">
      <module file="langraph.py" purpose="LangGraph node/edge auto-instrumentation" />
      <module file="crewai.py" purpose="CrewAI task/agent instrumentation" />
      <module file="autogen.py" purpose="AutoGen message flow instrumentation" />
    </dir>
    <dir name="_internal/">
      <module file="clock.py" purpose="Monotonic clock for span timing" />
      <module file="buffer.py" purpose="Ring buffer for span batching" />
      <module file="transport.py" purpose="HTTP/retry transport with exponential backoff" />
    </dir>
  </package>

  <package name="collector" path="packages/collector/">
    <module file="server.py" purpose="FastAPI ingestion endpoint (POST /v1/traces)" />
    <module file="redis_writer.py" purpose="Redis Streams XADD span writer" />
    <module file="validators.py" purpose="Incoming span payload validation" />
    <module file="auth.py" purpose="API key authentication middleware" />
    <module file="health.py" purpose="Health check and readiness probes" />
  </package>

  <package name="workers" path="packages/workers/">
    <module file="clickhouse_writer.py" purpose="Batch insert spans to ClickHouse" />
    <module file="security_engine.py" purpose="Prompt injection + PII scanner" />
    <module file="cost_calculator.py" purpose="LLM token usage cost aggregator" />
    <module file="consumer.py" purpose="Redis consumer group base class" />
    <dir name="rules/">
      <module file="injection.py" purpose="Prompt injection detection rules" />
      <module file="pii.py" purpose="PII pattern matching definitions" />
      <module file="anomaly.py" purpose="Loop and timeout anomaly detection" />
    </dir>
  </package>

  <package name="api" path="packages/api/">
    <module file="main.py" purpose="FastAPI application factory" />
    <dir name="routes/">
      <module file="traces.py" purpose="GET traces with filtering/pagination" />
      <module file="spans.py" purpose="GET individual span detail" />
      <module file="projects.py" purpose="Project CRUD + API key management" />
      <module file="security.py" purpose="Security alerts query" />
      <module file="analytics.py" purpose="Cost and usage analytics" />
      <module file="ws.py" purpose="WebSocket live trace streaming" />
    </dir>
    <module file="dependencies.py" purpose="Shared dependency injection" />
    <module file="middleware.py" purpose="CORS, auth, rate limit" />
    <module file="db.py" purpose="ClickHouse connection pool" />
    <module file="schemas.py" purpose="Pydantic response/request schemas" />
  </package>

  <package name="dashboard" path="packages/dashboard/">
    <dir name="components/">
      <file name="TraceTimeline.tsx" purpose="Waterfall timeline visualization" />
      <file name="SpanDetail.tsx" purpose="Span metadata inspector" />
      <file name="LiveFeed.tsx" purpose="Real-time WebSocket trace feed" />
      <file name="SecurityPanel.tsx" purpose="Threat alerts + PII warnings" />
      <file name="CostChart.tsx" purpose="Token usage cost chart" />
      <file name="TraceSearch.tsx" purpose="Full-text trace search with filters" />
      <file name="ProjectSwitcher.tsx" purpose="Multi-project selector" />
    </dir>
    <dir name="pages/">
      <file name="Dashboard.tsx" purpose="Overview metrics + recent traces" />
      <file name="TraceView.tsx" purpose="Single trace deep dive" />
      <file name="Security.tsx" purpose="Security alerts page" />
      <file name="Analytics.tsx" purpose="Cost + usage analytics" />
      <file name="Settings.tsx" purpose="API keys + project config" />
    </dir>
    <dir name="hooks/">
      <file name="useTraces.ts" purpose="React Query trace data fetching" />
      <file name="useWebSocket.ts" purpose="WebSocket connection manager" />
      <file name="useProject.ts" purpose="Active project context" />
    </dir>
  </package>

  <dir name="deploy/">
    <file name="docker-compose.yml" purpose="Full stack orchestration" />
    <file name="docker-compose.dev.yml" purpose="Dev overrides with hot reload" />
    <file name=".env.example" purpose="Environment variable template" />
    <dir name="clickhouse/" file="init.sql" purpose="ClickHouse schema bootstrap" />
    <dir name="redis/" file="redis.conf" purpose="Redis memory tuning" />
    <dir name="nginx/" file="default.conf" purpose="Reverse proxy + TLS" />
  </dir>
</file_structure>


<!-- ═══════════════════════════════════════════════════════════════════ -->
<!--                         DATA MODELS                               -->
<!-- ═══════════════════════════════════════════════════════════════════ -->

<data_models>

  <model name="Span">
    <field name="trace_id" type="UUID" description="Groups all spans in one agent execution" />
    <field name="span_id" type="UUID" description="Unique ID for this operation" />
    <field name="parent_span_id" type="Nullable(UUID)" description="Parent span (tree structure)" />
    <field name="name" type="String" description="Operation name: llm.chat, tool.call, memory.read" />
    <field name="start_time" type="DateTime64(6)" description="Nanosecond-precision start" />
    <field name="end_time" type="DateTime64(6)" description="Nanosecond-precision end" />
    <field name="duration_ms" type="UInt32" description="Computed duration in milliseconds" />
    <field name="status" type="String" description="OK or ERROR" />
    <field name="service_name" type="String" description="Service/project identifier" />
    <field name="attributes" type="Map(String, String)">
      Key-value pairs: llm.model, llm.tokens.in, llm.tokens.out, llm.cost,
      tool.name, tool.input, tool.output, memory.key, memory.action,
      error.message, error.type, security.flags, agentstack.framework
    </field>
    <field name="events" type="Nested(name String, timestamp DateTime64(6), attributes Map(String,String))" />
    <field name="project_id" type="String" description="Which project this belongs to" />
    <field name="api_key_hash" type="String" description="SHA-256 hash of the sending API key" />
  </model>

  <model name="SecurityAlert">
    <field name="alert_id" type="UUID" />
    <field name="trace_id" type="UUID" />
    <field name="span_id" type="UUID" />
    <field name="timestamp" type="DateTime64(6)" />
    <field name="severity" type="Enum('LOW','MEDIUM','HIGH','CRITICAL')" />
    <field name="rule_name" type="String" description="e.g. prompt_injection_jailbreak" />
    <field name="description" type="String" />
    <field name="evidence" type="String" description="Excerpt of offending content" />
  </model>

  <model name="CostMetric">
    <field name="trace_id" type="UUID" />
    <field name="model" type="String" description="e.g. gpt-4, claude-3-opus" />
    <field name="prompt_tokens" type="UInt32" />
    <field name="completion_tokens" type="UInt32" />
    <field name="cost_usd" type="Float64" />
    <field name="timestamp" type="DateTime64(6)" />
  </model>

</data_models>


<!-- ═══════════════════════════════════════════════════════════════════ -->
<!--                       DATABASE SCHEMAS                            -->
<!-- ═══════════════════════════════════════════════════════════════════ -->

<database engine="ClickHouse 24.x">
  <table name="spans" engine="MergeTree()" order_by="(service_name, start_time, trace_id)" ttl="start_time + INTERVAL 90 DAY">
    trace_id UUID, span_id UUID, parent_span_id Nullable(UUID), name String,
    start_time DateTime64(6), end_time DateTime64(6), duration_ms UInt32,
    service_name LowCardinality(String), attributes Map(String, String),
    status LowCardinality(String),
    events Nested(name String, timestamp DateTime64(6), attributes Map(String, String))
  </table>

  <table name="security_alerts" engine="MergeTree()" order_by="(severity, timestamp)">
    alert_id UUID, trace_id UUID, timestamp DateTime64(6),
    severity Enum('LOW','MEDIUM','HIGH','CRITICAL'), rule_name String, evidence String
  </table>

  <table name="cost_metrics" engine="SummingMergeTree()" order_by="(timestamp, model)">
    trace_id UUID, model LowCardinality(String), prompt_tokens UInt32,
    completion_tokens UInt32, cost_usd Float64, timestamp DateTime64(6)
  </table>
</database>


<!-- ═══════════════════════════════════════════════════════════════════ -->
<!--                         API REFERENCE                             -->
<!-- ═══════════════════════════════════════════════════════════════════ -->

<api base_url="http://localhost:8000/api/v1">

  <!-- INGESTION (Collector port 4318) -->
  <endpoint method="POST" path="/v1/traces" component="Collector">
    <headers>Content-Type: application/x-protobuf, X-API-Key: {key}</headers>
    <responses>
      <response code="202">Accepted — queued to Redis</response>
      <response code="401">Invalid API Key</response>
      <response code="400">Invalid Protobuf schema</response>
      <response code="413">Payload > 5MB</response>
    </responses>
  </endpoint>

  <!-- TRACES -->
  <endpoint method="GET" path="/traces">
    <params>limit(int,50), offset(int,0), project_id(uuid), start_time(iso8601), end_time(iso8601), status(OK|ERROR)</params>
    <response>{"items": [...], "total": 1540}</response>
  </endpoint>

  <endpoint method="GET" path="/traces/{trace_id}">
    <response>{"trace_id": "...", "spans": [...]}</response>
  </endpoint>

  <!-- ANALYTICS -->
  <endpoint method="GET" path="/analytics/cost">
    <params>interval(hour|day|week)</params>
    <response>{"series": [{"time":"...","cost":1.45}], "total_period_cost": 3.55}</response>
  </endpoint>

  <!-- PROJECTS -->
  <endpoint method="POST" path="/projects">
    <body>{"name": "My Agent"}</body>
    <response code="201">{"project_id": "...", "api_key": "as_live_..."}</response>
  </endpoint>

  <!-- SECURITY -->
  <endpoint method="GET" path="/security/alerts">
    <params>severity, project_id, limit, offset</params>
  </endpoint>

  <!-- WEBSOCKET -->
  <endpoint method="WS" path="/ws/traces">
    Live stream — pushes new spans as JSON in real-time via Redis XREAD tail.
  </endpoint>

  <!-- PRIVACY / COMPLIANCE -->
  <endpoint method="GET" path="/privacy/export/{user_id}">GDPR Right to Access</endpoint>
  <endpoint method="DELETE" path="/privacy/purge/{user_id}">GDPR Right to Erasure</endpoint>

</api>


<!-- ═══════════════════════════════════════════════════════════════════ -->
<!--                    CONFIGURATION (ENV VARS)                       -->
<!-- ═══════════════════════════════════════════════════════════════════ -->

<configuration>
  <!-- SDK -->
  <var name="AGENTSTACK_API_KEY" component="SDK" required="true" />
  <var name="AGENTSTACK_COLLECTOR_URL" component="SDK" default="http://localhost:4318" />
  <var name="AGENTSTACK_ENABLED" component="SDK" default="true" />
  <var name="AGENTSTACK_BATCH_SIZE" component="SDK" default="64" />
  <var name="AGENTSTACK_EXPORT_INTERVAL" component="SDK" default="5000" description="ms before flush" />
  <var name="AGENTSTACK_MAX_QUEUE_SIZE" component="SDK" default="2048" />
  <var name="AGENTSTACK_LOG_LEVEL" component="SDK" default="INFO" />
  <var name="AGENTSTACK_DEBUG" component="SDK" default="false" description="Enable stderr logging" />

  <!-- Infrastructure -->
  <var name="REDIS_URL" component="Collector" default="redis://localhost:6379" />
  <var name="CLICKHOUSE_HOST" component="Writer" default="localhost" />
  <var name="CLICKHOUSE_PORT" component="Writer" default="9000" />
  <var name="CLICKHOUSE_USER" component="Writer" default="default" />
  <var name="CLICKHOUSE_PASSWORD" component="Writer" default="" />
  <var name="CLICKHOUSE_DB" component="Writer" default="agentstack" />

  <!-- Workers -->
  <var name="SECURITY_RULES_PATH" component="Worker" default="./rules" />
  <var name="COST_MODEL_REFRESH_RATE" component="Worker" default="3600" description="seconds" />

  <!-- API -->
  <var name="JWT_SECRET_KEY" component="API" required="true" />
  <var name="JWT_ALGORITHM" component="API" default="HS256" />

  <!-- Dashboard -->
  <var name="DASHBOARD_PORT" component="Dashboard" default="3000" />
  <var name="VITE_API_BASE_URL" component="Dashboard" default="/api/v1" />
</configuration>


<!-- ═══════════════════════════════════════════════════════════════════ -->
<!--                        DATA FLOW SUMMARY                          -->
<!-- ═══════════════════════════════════════════════════════════════════ -->

<data_flow>
  <step n="1">Developer's @observe decorator wraps agent function. SDK creates span with trace_id, timing, attributes. Overhead less than 5ms.</step>
  <step n="2">SDK batches spans (64 OR 5s). Sends ONE HTTP POST /v1/traces as OTLP Protobuf gzip with X-API-Key header.</step>
  <step n="3">Collector validates API key + schema + size. Serializes to MsgPack. XADD to Redis spans.ingest. Returns 202.</step>
  <step n="4">Three parallel Redis consumer groups process: Writer → batch INSERT ClickHouse, Security → scan + alert, Cost → calculate + INSERT.</step>
  <step n="5">Dashboard queries API (FastAPI) which runs SQL against ClickHouse. Results in less than 500ms.</step>
  <step n="6">Live view: Dashboard opens WebSocket → API tails Redis → pushes new spans as JSON instantly.</step>
</data_flow>


<!-- ═══════════════════════════════════════════════════════════════════ -->
<!--                      FAILURE / RESILIENCE                         -->
<!-- ═══════════════════════════════════════════════════════════════════ -->

<failure_modes>
  <failure component="Collector Down">
    SDK retries 3x with exponential backoff. On exhaustion, writes to local SQLite.
    Auto-replays when collector returns. Developer impact: ZERO.
  </failure>
  <failure component="Redis Down">
    Collector buffers in-memory (max 10K spans). Returns HTTP 429 when full.
    Retries Redis every 5s. Spans delayed but not lost.
  </failure>
  <failure component="ClickHouse Down">
    Writer does NOT ACK Redis — spans stay buffered. Redis holds ~1M spans (~2.7hrs at 100K/s).
    Writer retries with backoff. Dashboard shows stale data. Full replay on recovery.
  </failure>
</failure_modes>


<!-- ═══════════════════════════════════════════════════════════════════ -->
<!--                     SECURITY ENGINE DETAILS                       -->
<!-- ═══════════════════════════════════════════════════════════════════ -->

<security_engine>
  <detection name="Prompt Injection">
    500+ known patterns via Bloom Filter. Scans input + output fields.
    Patterns: "ignore previous instructions", "DAN mode", system override, role confusion.
  </detection>
  <detection name="PII Leakage">
    Regex: SSN (\d{3}-\d{2}-\d{4}), Email, Credit Card (\d{4}-\d{4}-\d{4}-\d{4}),
    Phone, AWS Keys, OpenAI Keys. Replaces with [REDACTED].
  </detection>
  <detection name="Anomaly">
    Tracks average duration per trace. Flags traces > 3σ from mean (infinite loops).
    Token explosion detection. Timeout chain detection.
  </detection>
  <scoring>
    Weighted sum across detectors → threshold: LOW(0-29) / MEDIUM(30-59) / HIGH(60-84) / CRITICAL(85-100).
    Alert actions: INSERT to ClickHouse, XADD to alerts.live, optional Slack/PagerDuty webhook.
  </scoring>
</security_engine>


<!-- ═══════════════════════════════════════════════════════════════════ -->
<!--                    KEY DIFFERENTIATOR: TIME MACHINE                -->
<!-- ═══════════════════════════════════════════════════════════════════ -->

<time_machine>
  <concept>
    Replay any failed agent run with exact original inputs, memory state, and tool context.
    Developer watches step-by-step, identifies exact moment of failure, applies fix, replays with fix.
    Turns hours of debugging into minutes.
  </concept>
  <flow>
    1. Agent fails in production → full trace saved
    2. Developer finds failed trace in dashboard
    3. Sees exact step where it broke (e.g., "Step 7: LLM Hallucinated")
    4. Clicks Replay → Time Machine restores exact inputs + state + context
    5. Agent re-runs in debug mode → developer watches step-by-step
    6. Changes prompt → replays → agent succeeds → deploy fix
  </flow>
</time_machine>


<!-- ═══════════════════════════════════════════════════════════════════ -->
<!--                       CODING STANDARDS                            -->
<!-- ═══════════════════════════════════════════════════════════════════ -->

<coding_rules>

  <rule scope="Python (Backend + SDK)">
    - Async First: All I/O (Redis, ClickHouse) MUST be asynchronous.
    - Strong typing with Pydantic models. No untyped dicts in internal functions.
    - SDK must NEVER crash the user's app. Wrap all calls in try/except, log to stderr only if debug=True.
    - Serialization: MsgPack for internal (Redis), Protobuf for external (OTLP).
    - Linting/Formatting: RUFF for both.
    - Python version: >= 3.10.
  </rule>

  <rule scope="ClickHouse">
    - ALWAYS use async_insert=1 or batched inserts. NEVER single-row inserts.
    - Use MergeTree engines. Prefer LowCardinality(String) for repetitive columns.
    - Refer to Section 4.7 of PROJECT_DOCUMENTATION.txt for canonical schemas.
  </rule>

  <rule scope="Frontend (React)">
    - TanStack Query for ALL API calls. No useEffect for data fetching.
    - Tailwind CSS utility classes. No inline styles.
    - Shadcn UI components from @/components/ui.
    - Build: Vite. TypeScript strict mode.
  </rule>

  <rule scope="General">
    - Be concise. Show diffs, not full files, unless requested.
    - Always add standard copyright/license header to new files.
    - Check PROJECT_DOCUMENTATION.txt before answering architectural questions.
    - Do NOT hallucinate table schemas — use the defined schemas above.
  </rule>

</coding_rules>


<!-- ═══════════════════════════════════════════════════════════════════ -->
<!--                       COMPLIANCE (GDPR + EU AI ACT)               -->
<!-- ═══════════════════════════════════════════════════════════════════ -->

<compliance>
  <gdpr>
    PII redacted at source (SDK). 90-day data retention (configurable).
    Right to Access: GET /privacy/export/{user_id}.
    Right to Erasure: DELETE /privacy/purge/{user_id}.
    Data Minimization via PII Sanitizer.
  </gdpr>
  <eu_ai_act>
    Article 13 (Transparency): Full audit trail of AI decisions via trace logs.
    Article 14 (Human Oversight): Post-hoc review via dashboard + automated alerts.
    Article 15 (Robustness): Error rate monitoring, adversarial attack detection.
  </eu_ai_act>
</compliance>


<!-- ═══════════════════════════════════════════════════════════════════ -->
<!--                         BUILD PHASES                              -->
<!-- ═══════════════════════════════════════════════════════════════════ -->

<roadmap>
  <phase n="1" name="MVP (Local-Only)" effort="~40hrs / 12 days">
    SDK core (@observe, span model, context), PII sanitizer, local SQLite storage,
    CLI trace viewer, LangGraph hooks, tests + CI.
    Result: pip install agentstack → @observe → see traces in terminal.
  </phase>
  <phase n="2" name="Server + Web Dashboard" effort="~70hrs / 18 days">
    FastAPI server, SQLite backend, SDK HTTP export, React dashboard,
    Trace Timeline, WebSocket live feed, Auth + API keys, integration tests.
    Result: Open browser → see trace timelines → click span details → watch live.
  </phase>
  <phase n="3" name="Production Scale" effort="~80hrs / 20 days">
    Redis Streams, dedicated Collector, ClickHouse schema + migrations, CH Writer worker,
    Security Engine, Cost Calculator, Security/Analytics UI, Docker Compose,
    load testing (k6: 100K spans/sec), documentation.
    Result: 100K spans/sec, security scanning, one-command Docker deploy.
  </phase>
</roadmap>


<!-- ═══════════════════════════════════════════════════════════════════ -->
<!--                       DEPLOYMENT (DOCKER)                         -->
<!-- ═══════════════════════════════════════════════════════════════════ -->

<deployment>
  <network>agentstack-net (Docker bridge)</network>
  <services>
    <service name="nginx" port="80/443" purpose="TLS termination, reverse proxy" />
    <service name="collector" port="4318 (internal)" replicas="2" />
    <service name="api" port="8000 (internal)" replicas="2" />
    <service name="dashboard" port="3000 (internal)" purpose="Static files via Nginx" />
    <service name="worker-writer" replicas="1" />
    <service name="worker-security" replicas="1" />
    <service name="worker-cost" replicas="1" />
    <service name="redis" port="6379" volume="redis-data (AOF)" />
    <service name="clickhouse" port="8123/9000" volume="ch-data (MergeTree)" />
  </services>
  <volumes>redis-data, ch-data, nginx-certs</volumes>
</deployment>


<!-- ═══════════════════════════════════════════════════════════════════ -->
<!--                     DEVELOPER SETUP                               -->
<!-- ═══════════════════════════════════════════════════════════════════ -->

<dev_setup>
  <prerequisites>Docker Desktop >= 4.25, Python >= 3.10, Node.js >= 20 LTS, GNU Make</prerequisites>
  <steps>
    1. git clone → cd agentstack
    2. ./scripts/dev-setup.sh (venv, pip, npm install, mkcert, Docker Redis+CH)
    3. make run-api (FastAPI on :8000 with --reload)
    4. make run-workers (CH Writer + Security + Cost)
    5. cd packages/dashboard → npm run dev (Vite on :5173)
  </steps>
  <testing>
    Unit: pytest packages/sdk-python/tests, pytest packages/api/tests (80% coverage required)
    Integration: pytest tests/integration (testcontainers for Redis/CH)
    E2E: cd packages/dashboard → npm run test:e2e (Playwright)
  </testing>
</dev_setup>


<!-- ═══════════════════════════════════════════════════════════════════ -->
<!--              STEP-BY-STEP IMPLEMENTATION GUIDE                    -->
<!--     Build in this EXACT order. One step = one AI session.         -->
<!--     Each step lists: files, deps, acceptance criteria, prompt.    -->
<!-- ═══════════════════════════════════════════════════════════════════ -->

<implementation_steps>

  <!-- ════════════════════════════════════════════════════════════════ -->
  <!--                  PHASE 1: MVP (Local-Only Mode)                -->
  <!--                  Steps 1–6 | ~40 hours | 12 days               -->
  <!--         Goal: pip install agentstack → @observe → see traces   -->
  <!-- ════════════════════════════════════════════════════════════════ -->

  <step n="1" name="SDK Core — Span Model + Tracer + Context" phase="1" effort="12hrs">
    <description>
      Build the foundation: the Span data model, Tracer singleton, and async context
      propagation. This is the heart of the SDK — everything else builds on it.
    </description>
    <files_to_create>
      packages/sdk-python/pyproject.toml              — Package metadata, deps: pydantic, opentelemetry-api
      packages/sdk-python/src/agentstack/__init__.py   — Public API exports: observe, init, Tracer
      packages/sdk-python/src/agentstack/models.py     — Pydantic models: SpanModel, TraceModel, SpanStatus enum
      packages/sdk-python/src/agentstack/tracer.py     — Tracer singleton, Span class with start/end/set_attribute/add_event
      packages/sdk-python/src/agentstack/context.py    — contextvars-based trace_id + parent_span_id propagation (async-safe)
      packages/sdk-python/src/agentstack/config.py     — Config class reading from env vars (AGENTSTACK_API_KEY, _ENABLED, _BATCH_SIZE, etc.)
      packages/sdk-python/src/agentstack/_internal/__init__.py
      packages/sdk-python/src/agentstack/_internal/clock.py — Monotonic nanosecond clock wrapper
    </files_to_create>
    <depends_on>Nothing — this is the starting point.</depends_on>
    <acceptance_criteria>
      - Can create a Span with trace_id, span_id, parent_id, name, timestamps, attributes
      - Tracer.get_tracer() returns singleton
      - Context propagation works: nested spans auto-link parent_id via contextvars
      - Config loads all AGENTSTACK_* env vars with correct defaults
      - All models validate with Pydantic
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 1: SDK Core. Create the Span pydantic model (models.py), Tracer singleton (tracer.py),
      context propagation with contextvars (context.py), config from env vars (config.py), and clock utility.
      Follow the schemas defined in the architecture. Python 3.10+, strong typing, async-safe context."
    </prompt_to_use>
  </step>

  <step n="2" name="SDK — @observe Decorator" phase="1" effort="4hrs">
    <description>
      Build the @observe decorator that wraps sync and async functions.
      Captures args, result, errors, timing. This is what developers actually use.
    </description>
    <files_to_create>
      packages/sdk-python/src/agentstack/decorator.py  — @observe decorator (sync + async support)
    </files_to_create>
    <depends_on>Step 1 (Tracer, Span, Context)</depends_on>
    <acceptance_criteria>
      - @observe works on sync functions: creates span, captures args/result/errors, calls span.end()
      - @observe works on async functions: same but with async/await
      - @observe(name="custom") allows custom span names
      - Exceptions are re-raised after recording — SDK never swallows errors
      - All SDK code wrapped in try/except — decorator never crashes user's function
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 2: @observe decorator in decorator.py. Must support both sync and async functions.
      Captures function args, kwargs, return value, and exceptions as span attributes.
      Uses Tracer.get_tracer() and context propagation from Step 1. SDK must NEVER crash the user's app."
    </prompt_to_use>
  </step>

  <step n="3" name="SDK — PII Sanitizer" phase="1" effort="4hrs">
    <description>
      Build the regex-based PII scrubber that runs on all span attributes before export.
      Catches SSN, email, credit cards, phone numbers, API keys.
    </description>
    <files_to_create>
      packages/sdk-python/src/agentstack/sanitizer.py  — scrub_pii() function with regex patterns
    </files_to_create>
    <depends_on>Step 1 (Span model has attributes dict)</depends_on>
    <acceptance_criteria>
      - scrub_pii(attributes_dict) returns sanitized dict with [REDACTED] replacements
      - Detects: SSN (\d{3}-\d{2}-\d{4}), Email, Credit Card (\d{4}-\d{4}-\d{4}-\d{4}), Phone, AWS keys, OpenAI keys
      - Does NOT modify non-PII content
      - Handles nested values and edge cases (empty strings, None)
      - Fast enough for hot path (< 1ms per span)
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 3: PII Sanitizer in sanitizer.py. Create scrub_pii() that takes a dict of span attributes
      and replaces PII matches with [REDACTED]. Regex patterns for: SSN, email, credit card, phone, AWS keys,
      OpenAI keys. Must be fast (< 1ms). Handle edge cases."
    </prompt_to_use>
  </step>

  <step n="4" name="SDK — Local Storage (SQLite Fallback)" phase="1" effort="8hrs">
    <description>
      Build the local storage layer: JSON file export + SQLite database for offline span storage.
      This is the fallback when the collector is unreachable.
    </description>
    <files_to_create>
      packages/sdk-python/src/agentstack/local_store.py — SQLite storage: save_span(), get_unsent(), mark_sent(), export_json()
      packages/sdk-python/src/agentstack/_internal/buffer.py — Ring buffer for in-memory span batching
    </files_to_create>
    <depends_on>Step 1 (Span model), Step 3 (Sanitizer runs before storage)</depends_on>
    <acceptance_criteria>
      - save_span(span) persists to .agentstack.db SQLite file
      - get_unsent_spans() returns all spans not yet exported
      - mark_as_sent(span_ids) updates sent status
      - export_to_json(path) writes spans to a JSON file
      - Ring buffer holds up to MAX_QUEUE_SIZE spans in memory
      - Thread-safe operations
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 4: Local Storage. Create local_store.py with SQLite-backed span persistence
      (.agentstack.db). Methods: save_span, get_unsent_spans, mark_as_sent, export_to_json.
      Also create _internal/buffer.py with a thread-safe ring buffer (default 2048 capacity).
      This is the fallback when collector is down."
    </prompt_to_use>
  </step>

  <step n="5" name="SDK — Batch Exporter + HTTP Transport" phase="1" effort="6hrs">
    <description>
      Build the batch span processor and HTTP transport layer.
      Batches spans, sends via OTLP/HTTP, handles retries with exponential backoff.
      Falls back to local_store when all retries fail.
    </description>
    <files_to_create>
      packages/sdk-python/src/agentstack/exporter.py — BatchSpanProcessor: collect, flush, export loop
      packages/sdk-python/src/agentstack/_internal/transport.py — HTTP client with retry logic + backoff
    </files_to_create>
    <depends_on>Step 1 (Span), Step 3 (Sanitizer), Step 4 (Local Store fallback)</depends_on>
    <acceptance_criteria>
      - BatchSpanProcessor.add(span) queues span into ring buffer
      - Auto-flushes when batch_size (64) reached OR interval (5s) elapsed
      - Sends POST to AGENTSTACK_COLLECTOR_URL with Protobuf payload + gzip + X-API-Key header
      - On failure: 3 retries with exponential backoff (1s, 2s, 4s)
      - On all retries exhausted: writes to local SQLite via local_store
      - Background thread runs export loop — non-blocking to user's code
      - Graceful shutdown: flush remaining spans on process exit
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 5: Batch Exporter + Transport. Create exporter.py with BatchSpanProcessor that
      batches spans (64 or 5s) and exports via background thread. Create _internal/transport.py
      with HTTP client, retry logic (3x exponential backoff), and fallback to local_store.py on failure.
      Must be non-blocking. Graceful shutdown on exit."
    </prompt_to_use>
  </step>

  <step n="6" name="SDK — LangGraph Auto-Instrumentation" phase="1" effort="4hrs">
    <description>
      Build framework hooks that auto-instrument LangGraph nodes and edges.
      When a developer uses LangGraph, spans are created automatically without manual @observe.
    </description>
    <files_to_create>
      packages/sdk-python/src/agentstack/frameworks/__init__.py — Framework auto-detection
      packages/sdk-python/src/agentstack/frameworks/langraph.py — LangGraph node/edge monkey-patching
      packages/sdk-python/src/agentstack/frameworks/crewai.py   — CrewAI stub (basic structure)
      packages/sdk-python/src/agentstack/frameworks/autogen.py  — AutoGen stub (basic structure)
    </files_to_create>
    <depends_on>Step 1 (Tracer), Step 2 (Decorator)</depends_on>
    <acceptance_criteria>
      - Auto-detects if langgraph is installed
      - Patches LangGraph StateGraph to auto-create spans for each node execution
      - Captures node name, input state, output state, duration as span attributes
      - CrewAI and AutoGen stubs exist with TODO markers but no crashes
      - Framework hooks are optional — SDK works fine without any framework
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 6: Framework auto-instrumentation. Create frameworks/__init__.py with auto-detection,
      langraph.py that monkey-patches LangGraph StateGraph to auto-create spans per node.
      Create stubs for crewai.py and autogen.py. Must be optional — SDK works without frameworks."
    </prompt_to_use>
  </step>

  <step n="7" name="SDK — Unit Tests + CI" phase="1" effort="4hrs">
    <description>
      Write comprehensive unit tests for all SDK components. Set up pytest and GitHub Actions CI.
    </description>
    <files_to_create>
      packages/sdk-python/tests/conftest.py           — Shared fixtures: mock spans, mock tracer, temp DB
      packages/sdk-python/tests/test_decorator.py     — @observe sync/async, error handling, custom names
      packages/sdk-python/tests/test_tracer.py        — Span creation, context propagation, singleton
      packages/sdk-python/tests/test_sanitizer.py     — PII detection: SSN, email, CC, edge cases
      packages/sdk-python/tests/test_exporter.py      — Batch logic, retry, fallback to SQLite
      packages/sdk-python/tests/test_context.py       — Async context propagation in concurrent tasks
      packages/sdk-python/Makefile                    — Dev commands: test, lint, build
      .github/workflows/ci.yml                        — GitHub Actions: lint (ruff) + test (pytest) on push
    </files_to_create>
    <depends_on>Steps 1–6 (all SDK modules)</depends_on>
    <acceptance_criteria>
      - All tests pass with pytest
      - 80%+ code coverage on SDK
      - CI runs on push: ruff check + ruff format --check + pytest
      - Makefile has: make test, make lint, make build
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 7: SDK tests + CI. Create unit tests for decorator, tracer, sanitizer, exporter, context.
      Create conftest.py with fixtures. Create Makefile with test/lint/build commands.
      Create .github/workflows/ci.yml for GitHub Actions. Target 80%+ coverage."
    </prompt_to_use>
  </step>

  <!-- ════════════════════════════════════════════════════════════════ -->
  <!--             PHASE 2: Server + Web Dashboard                    -->
  <!--             Steps 8–14 | ~70 hours | 18 days                   -->
  <!--     Goal: Web UI with trace timelines + live streaming          -->
  <!-- ════════════════════════════════════════════════════════════════ -->

  <step n="8" name="API Server — FastAPI + SQLite Backend" phase="2" effort="12hrs">
    <description>
      Build the FastAPI server with SQLite as the initial backend (Phase 2 uses SQLite,
      Phase 3 migrates to ClickHouse). REST endpoints for traces, projects, analytics.
    </description>
    <files_to_create>
      packages/api/pyproject.toml
      packages/api/src/api/__init__.py
      packages/api/src/api/main.py              — FastAPI app factory, lifespan, CORS
      packages/api/src/api/db.py                — SQLite connection manager (async via aiosqlite)
      packages/api/src/api/schemas.py           — Pydantic request/response models
      packages/api/src/api/dependencies.py      — Dependency injection: get_db, get_current_user
      packages/api/src/api/middleware.py         — CORS, rate limiting
    </files_to_create>
    <depends_on>Step 1 (Span model — shared data types)</depends_on>
    <acceptance_criteria>
      - FastAPI app starts on port 8000
      - SQLite database auto-creates tables on first run
      - Health check endpoint: GET /health returns 200
      - CORS configured for localhost:5173 (Vite dev)
      - Pydantic schemas match the Span/Alert/CostMetric models
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 8: FastAPI server foundation. Create main.py with app factory, db.py with async SQLite
      (aiosqlite), schemas.py with Pydantic models matching our Span/Alert schemas, and middleware.py
      with CORS for localhost:5173. Port 8000. Include health check endpoint."
    </prompt_to_use>
  </step>

  <step n="9" name="API Server — Route Endpoints" phase="2" effort="8hrs">
    <description>
      Build all REST route handlers: traces CRUD, projects, security alerts, analytics.
    </description>
    <files_to_create>
      packages/api/src/api/routes/__init__.py
      packages/api/src/api/routes/traces.py     — GET /traces (list, filter, paginate), GET /traces/{id}
      packages/api/src/api/routes/spans.py      — GET /spans/{id} (individual span detail)
      packages/api/src/api/routes/projects.py   — POST /projects, GET /projects, DELETE /projects/{id}
      packages/api/src/api/routes/security.py   — GET /security/alerts (filter by severity, project)
      packages/api/src/api/routes/analytics.py  — GET /analytics/cost (timeseries: hour/day/week)
    </files_to_create>
    <depends_on>Step 8 (FastAPI app, DB, schemas)</depends_on>
    <acceptance_criteria>
      - GET /api/v1/traces returns paginated list with filters (status, date range, project)
      - GET /api/v1/traces/{trace_id} returns full span tree
      - POST /api/v1/projects creates project + returns API key (shown once)
      - GET /api/v1/security/alerts returns filtered alerts
      - GET /api/v1/analytics/cost returns timeseries data
      - All endpoints return proper error codes (404, 422, etc.)
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 9: API route endpoints. Create all route files: traces.py (list + detail with pagination/filters),
      spans.py, projects.py (CRUD + API key generation), security.py (alerts), analytics.py (cost timeseries).
      Use the db.py and schemas.py from Step 8. Follow the API spec in the architecture."
    </prompt_to_use>
  </step>

  <step n="10" name="API Server — Ingestion Endpoint + Auth" phase="2" effort="8hrs">
    <description>
      Build the trace ingestion endpoint (POST /v1/traces) that receives spans from the SDK,
      and the authentication system (API keys for SDK, JWT for dashboard users).
    </description>
    <files_to_create>
      packages/collector/pyproject.toml
      packages/collector/src/collector/__init__.py
      packages/collector/src/collector/server.py       — POST /v1/traces endpoint
      packages/collector/src/collector/validators.py   — Payload validation
      packages/collector/src/collector/auth.py         — API key validation
      packages/collector/src/collector/health.py       — Health + readiness probes
      packages/api/src/api/routes/auth.py              — JWT login/register for dashboard
    </files_to_create>
    <depends_on>Step 8 (DB), Step 5 (SDK exporter sends to this endpoint)</depends_on>
    <acceptance_criteria>
      - POST /v1/traces accepts span batches with X-API-Key header
      - Validates API key against database
      - Validates span schema (rejects malformed payloads with 400)
      - Rejects payloads > 5MB with 413
      - Stores received spans in SQLite
      - Returns 202 Accepted on success
      - JWT auth works for dashboard: login, register, token refresh
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 10: Trace ingestion + auth. Create collector/server.py with POST /v1/traces that
      validates API key, validates span schema, rejects >5MB, stores in SQLite, returns 202.
      Create auth.py for JWT-based dashboard login. API keys for SDK, JWT for dashboard users."
    </prompt_to_use>
  </step>

  <step n="11" name="Dashboard — React App Setup + Layout" phase="2" effort="8hrs">
    <description>
      Initialize the React dashboard with Vite, Shadcn UI, Tailwind, React Router, and TanStack Query.
      Build the app shell: sidebar, header, routing, dark theme.
    </description>
    <files_to_create>
      packages/dashboard/                              — npx create-vite-app (React + TypeScript)
      packages/dashboard/src/main.tsx                  — Entry point with providers
      packages/dashboard/src/App.tsx                   — Root layout with React Router
      packages/dashboard/src/lib/api.ts                — Axios client configured for /api/v1
      packages/dashboard/src/lib/types.ts              — TypeScript interfaces (Span, Trace, Alert, etc.)
      packages/dashboard/src/lib/utils.ts              — Formatting helpers
      packages/dashboard/src/styles/globals.css        — Design tokens, dark theme, Tailwind config
      packages/dashboard/src/components/ProjectSwitcher.tsx
    </files_to_create>
    <depends_on>Step 8 (API server to query)</depends_on>
    <acceptance_criteria>
      - Vite dev server runs on port 5173
      - Dark theme with professional design (not plain/boring)
      - Sidebar navigation: Dashboard, Traces, Security, Analytics, Settings
      - React Router routes configured for all pages
      - TanStack Query provider set up
      - Axios client configured with base URL and auth interceptor
      - TypeScript interfaces match backend Pydantic schemas
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 11: React dashboard setup. Initialize Vite + React + TypeScript. Install Shadcn UI,
      Tailwind, React Router, TanStack Query. Build app shell with dark-themed sidebar (Dashboard, Traces,
      Security, Analytics, Settings). Create api.ts client, types.ts interfaces, and globals.css with
      premium dark design tokens. Make it look STUNNING, not basic."
    </prompt_to_use>
  </step>

  <step n="12" name="Dashboard — Trace Timeline + Span Detail" phase="2" effort="12hrs">
    <description>
      Build the core visualization: waterfall timeline showing span durations and nesting,
      plus a detail panel that shows all span attributes when clicked.
    </description>
    <files_to_create>
      packages/dashboard/src/pages/Dashboard.tsx         — Overview page with metrics cards
      packages/dashboard/src/pages/TraceView.tsx         — Single trace view with timeline + detail
      packages/dashboard/src/components/TraceTimeline.tsx — Waterfall/Gantt chart visualization
      packages/dashboard/src/components/SpanDetail.tsx    — Span inspector side panel
      packages/dashboard/src/components/TraceSearch.tsx   — Search + filter bar
      packages/dashboard/src/hooks/useTraces.ts          — TanStack Query hooks for trace data
    </files_to_create>
    <depends_on>Step 11 (App shell), Step 9 (API endpoints to query)</depends_on>
    <acceptance_criteria>
      - Dashboard page shows: Total Traces, Error Rate, Avg Latency, Total Cost as metric cards
      - Traces list page with search, filter by status/date, pagination
      - Clicking a trace opens waterfall timeline showing all spans as horizontal bars
      - Bars are nested by parent-child relationship, colored by type (LLM=blue, tool=green, error=red)
      - Clicking a span opens detail panel showing all attributes, events, timing
      - Responsive layout, smooth animations
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 12: Trace Timeline + Span Detail. Create Dashboard.tsx with metrics overview,
      TraceView.tsx with waterfall timeline. Build TraceTimeline.tsx as a Gantt-chart showing span
      durations with parent-child nesting. Build SpanDetail.tsx as an inspector panel.
      Create useTraces.ts with TanStack Query. Colors: LLM=blue, tool=green, error=red.
      Must look premium with smooth animations."
    </prompt_to_use>
  </step>

  <step n="13" name="Dashboard — WebSocket Live Feed" phase="2" effort="8hrs">
    <description>
      Build real-time trace streaming: WebSocket connection from dashboard to API,
      showing new spans as they arrive in a live feed.
    </description>
    <files_to_create>
      packages/api/src/api/routes/ws.py                  — WebSocket endpoint
      packages/dashboard/src/components/LiveFeed.tsx      — Real-time span feed component
      packages/dashboard/src/hooks/useWebSocket.ts        — WebSocket connection + state manager
    </files_to_create>
    <depends_on>Step 9 (API), Step 11 (Dashboard shell)</depends_on>
    <acceptance_criteria>
      - WS /ws/traces endpoint streams new spans as JSON
      - Dashboard LiveFeed component shows spans appearing in real-time
      - Auto-reconnect on connection drop
      - Visual indicator: "● Live" when connected, "○ Disconnected" when not
      - New spans animate in smoothly (slide-in from top)
      - Can pause/resume the live feed
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 13: WebSocket live streaming. Create ws.py WebSocket endpoint that pushes new spans.
      Create LiveFeed.tsx component showing real-time span feed with slide-in animations.
      Create useWebSocket.ts hook with auto-reconnect. Show connection status indicator."
    </prompt_to_use>
  </step>

  <step n="14" name="Dashboard — Settings + API Tests" phase="2" effort="6hrs">
    <description>
      Build the Settings page (API key management, project config) and write integration tests
      for the API endpoints.
    </description>
    <files_to_create>
      packages/dashboard/src/pages/Settings.tsx          — API keys, project management
      packages/dashboard/src/hooks/useProject.ts         — Active project context
      packages/api/tests/conftest.py                     — Test client + fixtures
      packages/api/tests/test_traces.py                  — Trace endpoint tests
      packages/api/tests/test_ws.py                      — WebSocket tests
    </files_to_create>
    <depends_on>Steps 8–13 (full API + dashboard)</depends_on>
    <acceptance_criteria>
      - Settings page: create/delete projects, view/regenerate API keys, copy to clipboard
      - Project switcher works across all pages
      - API integration tests pass
      - WebSocket connection test passes
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 14: Settings page + API tests. Create Settings.tsx with project CRUD and API key management.
      Create useProject.ts hook. Write integration tests for trace endpoints and WebSocket in packages/api/tests/."
    </prompt_to_use>
  </step>

  <!-- ════════════════════════════════════════════════════════════════ -->
  <!--                PHASE 3: Production Scale                       -->
  <!--              Steps 15–24 | ~80 hours | 20 days                 -->
  <!--    Goal: 100K spans/sec, security, Docker, production-ready     -->
  <!-- ════════════════════════════════════════════════════════════════ -->

  <step n="15" name="Redis Streams — Event Bus Setup" phase="3" effort="8hrs">
    <description>
      Replace direct SQLite writes with Redis Streams as the event bus between Collector and Workers.
      Set up consumer groups for parallel processing.
    </description>
    <files_to_create>
      packages/collector/src/collector/redis_writer.py  — XADD to spans.ingest stream
      packages/workers/pyproject.toml
      packages/workers/src/workers/__init__.py
      packages/workers/src/workers/consumer.py          — Base consumer group class (XREADGROUP + XACK)
      deploy/redis/redis.conf                           — appendonly yes, maxmemory 2gb, noeviction
    </files_to_create>
    <depends_on>Step 10 (Collector)</depends_on>
    <acceptance_criteria>
      - Collector writes spans to Redis Stream spans.ingest via XADD
      - MsgPack serialization for compact storage
      - Stream has MAXLEN ~1000000
      - Base consumer class supports: read batch, process, acknowledge
      - Three consumer groups created: writer-group, security-group, cost-group
      - Redis config has AOF persistence enabled
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 15: Redis Streams event bus. Update collector to XADD spans to Redis stream
      spans.ingest (MsgPack format). Create base consumer.py class with XREADGROUP + XACK pattern.
      Create redis.conf with AOF, 2GB max, noeviction. Set up 3 consumer groups."
    </prompt_to_use>
  </step>

  <step n="16" name="ClickHouse — Schema + Migration" phase="3" effort="8hrs">
    <description>
      Set up ClickHouse: create the production database schema, migration system,
      and connection pool manager.
    </description>
    <files_to_create>
      deploy/clickhouse/init.sql                        — CREATE TABLE spans, security_alerts, cost_metrics
      packages/api/src/api/db.py                        — ClickHouse async connection pool (replace SQLite)
      packages/api/alembic/env.py                       — Migration environment
      packages/api/alembic/versions/001_initial.py      — Initial schema migration
    </files_to_create>
    <depends_on>Step 8 (DB layer to replace)</depends_on>
    <acceptance_criteria>
      - init.sql creates all tables matching the schema specification exactly
      - MergeTree engines with correct ORDER BY and TTL
      - LowCardinality for service_name, status
      - SummingMergeTree for cost_metrics
      - Connection pool works with async ClickHouse driver (asynch)
      - API routes work with ClickHouse (replace SQLite queries)
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 16: ClickHouse schema. Create init.sql with spans (MergeTree, ORDER BY service_name/start_time/trace_id,
      TTL 90 days), security_alerts (MergeTree, ORDER BY severity/timestamp), cost_metrics (SummingMergeTree).
      Use LowCardinality for strings. Update db.py to use async ClickHouse connection pool."
    </prompt_to_use>
  </step>

  <step n="17" name="Worker — ClickHouse Writer" phase="3" effort="8hrs">
    <description>
      Build the worker that reads spans from Redis and batch-inserts them into ClickHouse.
    </description>
    <files_to_create>
      packages/workers/src/workers/clickhouse_writer.py — Batch INSERT worker (1000 spans or 1s)
      packages/workers/Dockerfile
    </files_to_create>
    <depends_on>Step 15 (Redis consumer base), Step 16 (ClickHouse schema)</depends_on>
    <acceptance_criteria>
      - Reads from Redis consumer group writer-group
      - Batches up to 1000 spans OR flushes every 1 second
      - Uses async_insert=1 or native batch INSERT
      - ACKs Redis messages only after successful ClickHouse INSERT
      - On ClickHouse failure: does NOT ACK, retries with backoff (infinite retry = no data loss)
      - Logs throughput metrics (spans/sec)
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 17: ClickHouse Writer worker. Extend consumer.py base class. Read from writer-group,
      batch 1000 spans or 1s, INSERT into ClickHouse. ACK only on success. Infinite retry on failure.
      Use async_insert=1. Create Dockerfile."
    </prompt_to_use>
  </step>

  <step n="18" name="Worker — Security Engine" phase="3" effort="12hrs">
    <description>
      Build the security scanner that analyzes every span for prompt injection,
      PII leaks, and anomalies. Generates alerts with severity scoring.
    </description>
    <files_to_create>
      packages/workers/src/workers/security_engine.py    — Main security worker
      packages/workers/src/workers/rules/__init__.py
      packages/workers/src/workers/rules/injection.py   — Prompt injection patterns (500+)
      packages/workers/src/workers/rules/pii.py         — PII detection regex
      packages/workers/src/workers/rules/anomaly.py     — Loop detection, token explosion
    </files_to_create>
    <depends_on>Step 15 (Redis consumer), Step 16 (ClickHouse for alert storage)</depends_on>
    <acceptance_criteria>
      - Reads from security-group consumer group
      - Scans span input + output for injection patterns (Bloom Filter for speed)
      - Scans for PII leaks (redundant with SDK sanitizer — defense in depth)
      - Detects anomalies: traces > 3σ duration, token explosion, repeated calls > 50x
      - Calculates threat score (0-100), maps to severity (LOW/MEDIUM/HIGH/CRITICAL)
      - On threat: INSERT alert to security_alerts + XADD to alerts.live Redis stream
      - ACKs Redis after processing
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 18: Security Engine worker. Create security_engine.py, rules/injection.py (500+ patterns
      with Bloom Filter), rules/pii.py (SSN, email, CC, AWS keys), rules/anomaly.py (3σ detection, loop detection).
      Threat scoring 0-100, severity levels. Write alerts to ClickHouse + Redis alerts.live stream."
    </prompt_to_use>
  </step>

  <step n="19" name="Worker — Cost Calculator" phase="3" effort="8hrs">
    <description>
      Build the cost calculator that extracts token counts and model info from spans,
      looks up pricing, and stores cost metrics.
    </description>
    <files_to_create>
      packages/workers/src/workers/cost_calculator.py   — Cost calculation worker
    </files_to_create>
    <depends_on>Step 15 (Redis consumer), Step 16 (ClickHouse for metrics)</depends_on>
    <acceptance_criteria>
      - Reads from cost-group consumer group
      - Extracts llm.model, llm.usage.prompt_tokens, llm.usage.completion_tokens from span attributes
      - Looks up model price from pricing catalog (gpt-4, gpt-3.5, claude-3, etc.)
      - Calculates cost = (prompt_tokens * input_price + completion_tokens * output_price) / 1000
      - INSERTs cost_metrics record into ClickHouse
      - Pricing catalog refreshable (configurable via COST_MODEL_REFRESH_RATE)
      - Handles missing/unknown models gracefully (logs warning, skips)
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 19: Cost Calculator worker. Read from cost-group, extract token counts + model from spans,
      look up pricing (GPT-4: $0.03/$0.06 per 1K, GPT-3.5: $0.0015/$0.002, Claude-3-Opus: $0.015/$0.075),
      calculate cost, INSERT into cost_metrics. Handle unknown models gracefully."
    </prompt_to_use>
  </step>

  <step n="20" name="Dashboard — Security Alerts Page" phase="3" effort="4hrs">
    <description>
      Build the Security page: list of alerts, filter by severity, click to jump to offending trace.
    </description>
    <files_to_create>
      packages/dashboard/src/pages/Security.tsx          — Security alerts dashboard
      packages/dashboard/src/components/SecurityPanel.tsx — Alert cards with severity badges
    </files_to_create>
    <depends_on>Step 11 (Dashboard shell), Step 18 (Security Engine produces alerts)</depends_on>
    <acceptance_criteria>
      - Shows list of security alerts with severity badges (color-coded)
      - Filter by severity: LOW (gray), MEDIUM (yellow), HIGH (orange), CRITICAL (red)
      - Each alert shows: rule name, description, timestamp, evidence excerpt
      - Click alert → navigates to the offending trace/span
      - Real-time updates via WebSocket when new alerts arrive
      - Empty state when no alerts: "All clear — no threats detected"
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 20: Security alerts page. Create Security.tsx with alert list, severity badges
      (color-coded), filter by severity, click-to-trace navigation. Create SecurityPanel.tsx component.
      Real-time updates via WebSocket. Premium dark UI with proper alert styling."
    </prompt_to_use>
  </step>

  <step n="21" name="Dashboard — Cost Analytics Page" phase="3" effort="4hrs">
    <description>
      Build the Analytics page: cost charts, token usage over time, per-model breakdown.
    </description>
    <files_to_create>
      packages/dashboard/src/pages/Analytics.tsx         — Cost analytics dashboard
      packages/dashboard/src/components/CostChart.tsx    — Token usage / cost charts (Recharts)
    </files_to_create>
    <depends_on>Step 11 (Dashboard shell), Step 19 (Cost Calculator produces metrics)</depends_on>
    <acceptance_criteria>
      - Line chart: total cost over time (hourly/daily/weekly toggle)
      - Bar chart: cost breakdown by model (GPT-4 vs Claude vs etc.)
      - Metric cards: Total Spend, Avg Cost per Trace, Most Expensive Model
      - Date range picker for filtering
      - Responsive charts that look great on dark theme
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 21: Cost Analytics page. Create Analytics.tsx with line chart (cost over time),
      bar chart (per-model breakdown), metric cards (total spend, avg cost, most expensive model).
      Use Recharts. Create CostChart.tsx component. Dark theme, date range picker, interval toggle."
    </prompt_to_use>
  </step>

  <step n="22" name="Docker Compose — Full Stack Deployment" phase="3" effort="8hrs">
    <description>
      Create Docker Compose configuration for the entire stack: all services, Nginx reverse proxy,
      volumes, networking, and environment variables.
    </description>
    <files_to_create>
      deploy/docker-compose.yml                         — Production: all 9 services
      deploy/docker-compose.dev.yml                     — Dev overrides: hot reload, exposed ports
      deploy/.env.example                               — All environment variables with defaults
      deploy/nginx/default.conf                         — Reverse proxy: /api→API, /v1/traces→Collector, /→Dashboard
      packages/collector/Dockerfile
      packages/api/Dockerfile
      packages/dashboard/Dockerfile                     — Multi-stage: build → nginx serve
      packages/workers/Dockerfile
    </files_to_create>
    <depends_on>Steps 8–21 (all services must exist)</depends_on>
    <acceptance_criteria>
      - `docker compose up` starts entire stack from scratch
      - Nginx routes correctly: / → Dashboard, /api/* → API, /v1/traces → Collector
      - Services wait for dependencies (healthchecks: Redis, ClickHouse)
      - Volumes persist data across restarts
      - .env.example documents every required variable
      - Dev compose adds hot reload for Python + Vite
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 22: Docker Compose full stack. Create docker-compose.yml with all 9 services
      (nginx, collector x2, api x2, dashboard, worker-writer, worker-security, worker-cost, redis, clickhouse).
      Create nginx/default.conf for routing. Create all Dockerfiles. Create .env.example.
      Create docker-compose.dev.yml with hot reload overrides."
    </prompt_to_use>
  </step>

  <step n="23" name="Load Testing + Worker Tests" phase="3" effort="8hrs">
    <description>
      Write load tests to verify 100K spans/sec throughput and integration tests for all workers.
    </description>
    <files_to_create>
      scripts/benchmark.py                               — SDK overhead benchmarking
      scripts/seed-data.py                               — Generate sample traces for testing
      packages/workers/tests/test_security.py            — Security engine rule tests
      packages/workers/tests/test_writer.py              — ClickHouse writer batch tests
      packages/workers/tests/test_cost.py                — Cost calculator tests
    </files_to_create>
    <depends_on>Steps 17–19 (all workers)</depends_on>
    <acceptance_criteria>
      - benchmark.py measures SDK overhead (target: < 5ms per span)
      - seed-data.py generates realistic sample traces with various span types
      - Security engine tests: injection detection, PII detection, anomaly detection
      - Writer tests: batch insert, retry on failure, ACK behavior
      - Cost tests: correct calculation, unknown model handling
      - Load test target: system handles 100K spans/sec sustained
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 23: Tests + benchmarks. Create benchmark.py for SDK overhead measurement (<5ms target).
      Create seed-data.py to generate realistic sample traces. Write unit tests for security_engine,
      clickhouse_writer, and cost_calculator. Cover edge cases: batch failures, unknown models, false positives."
    </prompt_to_use>
  </step>

  <step n="24" name="Documentation + README" phase="3" effort="4hrs">
    <description>
      Write user-facing documentation: getting started guide, SDK reference, self-hosting guide.
    </description>
    <files_to_create>
      README.md                                          — Project overview, badges, quick start
      docs/getting-started.md                            — 5-minute setup guide
      docs/sdk-reference.md                              — Complete SDK API docs
      docs/self-hosting.md                               — Docker Compose deployment guide
      docs/security-model.md                             — Threat model and data handling
      scripts/dev-setup.sh                               — One-command dev environment setup
    </files_to_create>
    <depends_on>Steps 1–23 (everything built)</depends_on>
    <acceptance_criteria>
      - README has: logo, badges, one-line description, quick start, screenshot
      - Getting started: pip install → @observe → see traces in 5 minutes
      - SDK reference: every function, every config var, examples
      - Self-hosting: docker compose up → working stack
      - Security model: what data is collected, how PII is handled, compliance
      - dev-setup.sh works on Linux/Mac (creates venv, installs deps, starts Docker)
    </acceptance_criteria>
    <prompt_to_use>
      "Build Step 24: Documentation. Create README.md with badges and quick start. Create docs/:
      getting-started.md (5-min guide), sdk-reference.md (full API docs), self-hosting.md (Docker deploy),
      security-model.md (threat model). Create scripts/dev-setup.sh. Make it welcoming for open-source contributors."
    </prompt_to_use>
  </step>

</implementation_steps>

</agentstack_system_prompt>
