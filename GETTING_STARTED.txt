========================================================================
                      AGENTSTACK - GETTING STARTED
========================================================================
Welcome to AgentStack, the open-source observability platform for AI 
Agents! This guide explains exactly how another person (a developer) 
can take this project, start it up, and connect their own AI bots to 
it to see live execution traces, security metrics, and cost analysis.

========================================================================
PHASE 1: STARTING THE AGENTSTACK SERVER
========================================================================
Before you can monitor any AI agents, you need the AgentStack backend 
and frontend running on your machine.

1. Prerequisites:
   - Docker & Docker Compose installed
   - Node.js 18+ installed
   - Python 3.10+ installed

2. Start the Backend Infrastructure:
   AgentStack uses an advanced architecture with Redis streams and a 
   ClickHouse database. Don't worry, it's all automated.
   
   Open a terminal in the root folder and run:
   > cd deploy
   > docker compose up -d

   This spins up the databases and the ingestion APIs!

3. Start the Dashboard UI:
   To view your agents visually, you need the React Dashboard.
   
   Open a new terminal in the root folder:
   > cd agentstack/packages/dashboard
   > npm install
   > npm run dev
   
   Now open your browser to: http://localhost:5173

========================================================================
PHASE 2: GET YOUR API KEY
========================================================================
Your local AgentStack server is running! Now you need a key to send data.

1. In your browser (http://localhost:5173), go to "Settings".
2. Click "Create New Project" (Name it something like "My First Agent").
3. The dashboard will generate an API Key that looks like `ak_...`
4. Copy this API Key! You need it for your Python code.

========================================================================
PHASE 3: CONNECTING YOUR AI AGENT
========================================================================
Now, let's pretend you are writing your own AI agent in a totally 
different Python project. You want AgentStack to monitor it.

1. Install the AgentStack SDK via pip in your project:
   > pip install -e /path/to/AgentState/agentstack/packages/sdk-python

2. Set your Environment Variables in your terminal (or a .env file):
   > export AGENTSTACK_API_KEY="ak_your_copied_api_key_here"
   > export AGENTSTACK_BASE_URL="http://localhost:8000"

3. Instrument your code! You have 3 options depending on what you use:

--- OPTION A: Automatic CrewAI Tracking ---
If you build agents with CrewAI, AgentStack does everything automatically!
Just add ONE line of code at the top of your python file:

    from agentstack.frameworks import crewai
    crewai.instrument()  # <-- MAGIC: Traces everything automatically!

    from crewai import Agent, Task, Crew
    # ... the rest of your normal CrewAI code ...


--- OPTION B: Automatic AutoGen Tracking ---
If you use Microsoft AutoGen, it's also magical:

    from agentstack.frameworks import autogen
    autogen.instrument() # <-- MAGIC: Traces all AutoGen conversations!

    import autogen
    # ... the rest of your normal AutoGen code ...


--- OPTION C: Manual Tracing (For custom LangChain/OpenAI agents) ---
If you write your own custom logic, you can manually wrap blocks of code
so they appear as visual "Spans" in the dashboard.

    import os
    from agentstack import trace, span, flush

    @trace(name="My Awesome Agent Workflow")
    def run_my_agent(user_question):
        # The entire execution of this function is tracked
        
        @span("Database Search")
        def search_docs(q):
            # This shows up as a child visual block!
            return "Found some internal documentation."
            
        docs = search_docs(user_question)
        
        @span("LLM call")
        def call_openai():
            # You can track exactly how long the LLM takes
            return "Based on docs, here is the answer."
            
        return call_openai()

    # Run your agent
    run_my_agent("How do I use this?")
    
    # Crucial: Ensure all background telemetry is sent before script closes
    flush()

========================================================================
PHASE 4: VIEW THE MAGIC
========================================================================
1. Run your Python agent script.
2. Go back to your browser (http://localhost:5173).
3. Click on the "Traces" tab.
4. You will instantly see your agent's execution! 
   - You can see exactly how long every tool took.
   - You can see the exact prompts sent and responses received.
   - You can replay the execution chronologically using the Time Machine.
   - You can check the "Security" tab to see if your agent tried to 
     read any protected PII or execute malicious code!

That's it! The system is built to be a drop-in 'magic' monitoring layer 
for any enterprise AI engineering team.
